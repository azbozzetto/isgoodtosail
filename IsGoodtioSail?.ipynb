{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOlEw5ChgIo7DzGXNTmn/FS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/azbozzetto/isgoodtosail/blob/main/IsGoodtioSail%3F.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "anDf_3PEG_if",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Imports and conf\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def install(package):\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
        "\n",
        "packages = [\"flask\", \"geocoder\", \"pandas\", \"requests\", \"bs4\", \"numpy\", \"pytz\", \"selenium\",\"webdriver_manager\"]\n",
        "\n",
        "for package in packages:\n",
        "    try:\n",
        "        __import__(package)\n",
        "        print(f\"{package} is already installed.\")\n",
        "    except ImportError:\n",
        "        print(f\"{package} not found, installing...\")\n",
        "        install(package)\n",
        "\n",
        "# !apt install chromium-chromedriver\n",
        "\n",
        "import geocoder\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "import pytz\n",
        "from bs4 import BeautifulSoup\n",
        "from datetime import datetime\n",
        "from flask import Flask, request, jsonify\n",
        "\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import Select\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "# from webdriver_manager.chrome import ChromeDriverManager\n",
        "\n",
        "# Setting global variables for API configuration\n",
        "API_KEY = '024f6cfecb6489a8a498fea463be2050'\n",
        "API_LANG = 'es'\n",
        "API_UNITS = 'metric'\n",
        "API_FORECAST_N = '9'\n",
        "\n",
        "WEATHER_URL = \"https://api.openweathermap.org/data/2.5/forecast\"\n",
        "MAREAS_URL = 'http://www.hidro.gob.ar/oceanografia/Tmareas/Form_Tmareas.asp'\n",
        "PRONOSTICO_URL = 'http://www.hidro.gov.ar/oceanografia/pronostico.asp'\n",
        "\n",
        "GOOD_MIN_WIND = 5\n",
        "GOOD_MAX_WIND = 18\n",
        "BAD_WEATHER = ['LLUVIA', 'TORMENTA']\n",
        "MIN_TIDE = 0.4\n",
        "\n",
        "# Set up Selenium to use Chrome in headless mode\n",
        "CHROME_OPTIONS = Options()\n",
        "\n",
        "CHROME_OPTIONS.binary_location = \"/usr/bin/chromium-browser\"  #\"/usr/bin/chromium\"\n",
        "CHROME_OPTIONS.add_argument(\"--headless\")                     # Important for headless servers\n",
        "CHROME_OPTIONS.add_argument(\"--no-sandbox\")                   # Bypass OS security model\n",
        "CHROME_OPTIONS.add_argument(\"--disable-dev-shm-usage\")        # Overcome limited resource problems\n",
        "CHROME_OPTIONS.add_argument(\"--disable-gpu\")                  # Applicable if GPU acceleration isn't available\n",
        "CHROME_OPTIONS.add_argument(\"--window-size=1920x1080\")        # Set window size if needed\n",
        "# CHROME_OPTIONS.add_argument(\"--verbose\")\n",
        "# CHROME_OPTIONS.add_argument(\"--log-path=chromedriver.log\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title functions\n",
        "\n",
        "# Utility function to convert degrees to compass direction\n",
        "def degrees_to_compass(degrees):\n",
        "    compass_points = ['N', 'NE', 'E', 'SE', 'S', 'SW', 'W', 'NW', 'N']\n",
        "    index = int((degrees + 22.5) // 45) % 8\n",
        "    return compass_points[index]\n",
        "\n",
        "# Function to get current latitude and longitude\n",
        "def get_current_location():\n",
        "    g = geocoder.ip('me')\n",
        "    print(g)\n",
        "    return round(g.latlng[0], 2), round(g.latlng[1], 2)\n",
        "\n",
        "# Function to fetch weather data\n",
        "def fetch_weather(lat, lon):\n",
        "    params = {\n",
        "        \"lat\": lat,\n",
        "        \"lon\": lon,\n",
        "        \"lang\": API_LANG,\n",
        "        \"units\": API_UNITS,\n",
        "        \"appid\": API_KEY,\n",
        "        \"cnt\": API_FORECAST_N\n",
        "    }\n",
        "    response = requests.get(WEATHER_URL, params=params)\n",
        "    weather_json = response.json()\n",
        "    weather_df = pd.json_normalize(weather_json, record_path='list')\n",
        "    timezone = (weather_json['city']['timezone'] / 3600) * 60\n",
        "    city = weather_json['city']['name']\n",
        "    timezone = pytz.FixedOffset(timezone)\n",
        "    weather_df.drop(['pop','dt_txt','visibility','main.pressure','main.temp','main.feels_like','main.temp_min','main.temp_max','main.sea_level','main.grnd_level','main.humidity','main.temp_kf','clouds.all','sys.pod'], axis=1, inplace=True)\n",
        "\n",
        "    weather_df['datetime'] = pd.to_datetime(weather_df['dt'], unit='s', utc=True)\n",
        "    weather_df['datetime'] = weather_df['datetime'].dt.tz_convert(timezone)\n",
        "    weather_df['weather_clouds'] = weather_df['weather'].apply(lambda x: x[0]['description'].upper())\n",
        "    weather_df['wind_speed_knots'] = round(weather_df['wind.speed'] * 1.94384, 1)\n",
        "    weather_df['wind_gust_knots'] = round(weather_df.get('wind.gust', 0).fillna(0) * 1.94384, 1)\n",
        "    weather_df['wind_direction'] = weather_df['wind.deg'].apply(degrees_to_compass)\n",
        "\n",
        "    return weather_df\n",
        "\n",
        "# Function to calculate tide height with rule of 12ยบ\n",
        "def calculate_tide_height_rule_of_twelfths(low_tide_time, low_tide_height, high_tide_time, high_tide_height, forecast_time):\n",
        "    high_tide_height = float(high_tide_height)\n",
        "    low_tide_height = float(low_tide_height)\n",
        "    total_range = high_tide_height - low_tide_height\n",
        "    total_time = (high_tide_time - low_tide_time).total_seconds() / 3600\n",
        "    elapsed_time = (forecast_time - low_tide_time).total_seconds() / 3600\n",
        "\n",
        "    if elapsed_time <= 1:\n",
        "        tide_increment = total_range * (1/12)\n",
        "    elif elapsed_time <= 2:\n",
        "        tide_increment = total_range * (3/12)\n",
        "    elif elapsed_time <= 4:\n",
        "        tide_increment = total_range * (6/12)\n",
        "    elif elapsed_time <= 5:\n",
        "        tide_increment = total_range * (8/12)\n",
        "    else:\n",
        "        tide_increment = total_range * (9/12)\n",
        "\n",
        "    tide_height = low_tide_height + tide_increment\n",
        "    return tide_height\n",
        "\n",
        "# Function to calculate tide height\n",
        "def calculate_tide_height(forecast_time, tide_df):\n",
        "    for i in range(len(tide_df) - 1):\n",
        "        low_tide_time = tide_df.iloc[i]['datetime']\n",
        "        high_tide_time = tide_df.iloc[i + 1]['datetime']\n",
        "        low_tide_height = tide_df.iloc[i]['height']\n",
        "        high_tide_height = tide_df.iloc[i + 1]['height']\n",
        "\n",
        "        if low_tide_time <= forecast_time <= high_tide_time:\n",
        "            return calculate_tide_height_rule_of_twelfths(low_tide_time, low_tide_height, high_tide_time, high_tide_height, forecast_time)\n",
        "\n",
        "    return None\n",
        "\n",
        "# Function to generate tide table using Selenium\n",
        "def generate_tide_table(year, month, port):\n",
        "    MONTH_NAMES = {\n",
        "        '1': 'Enero', '2': 'Febrero', '3': 'Marzo', '4': 'Abril', '5': 'Mayo',\n",
        "        '6': 'Junio', '7': 'Julio', '8': 'Agosto', '9': 'Septiembre',\n",
        "        '10': 'Octubre', '11': 'Noviembre', '12': 'Diciembre'\n",
        "    }\n",
        "    month_name = MONTH_NAMES[str(month)]\n",
        "\n",
        "    driver = webdriver.Chrome(options=CHROME_OPTIONS)\n",
        "    try:\n",
        "        driver.get(MAREAS_URL)\n",
        "        WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.NAME, 'FAnio')))\n",
        "        Select(driver.find_element(By.NAME, 'FAnio')).select_by_visible_text(str(year))\n",
        "        Select(driver.find_element(By.NAME, 'Localidad')).select_by_visible_text(port)\n",
        "        Select(driver.find_element(By.NAME, 'FMes')).select_by_visible_text(month_name)\n",
        "        driver.find_element(By.NAME, 'B1').click()\n",
        "        WebDriverWait(driver, 10).until(EC.frame_to_be_available_and_switch_to_it((By.ID, 'tablasdemarea')))\n",
        "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'table')))\n",
        "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
        "        panel_bodies = soup.find_all('div', {'class': 'panel-body'})\n",
        "\n",
        "        # Initialize an empty DataFrame to store the combined table data\n",
        "        tide_table_df = pd.DataFrame()\n",
        "        table_dfs = []\n",
        "\n",
        "        # Loop through each panel-body and extract the table data\n",
        "        for panel_body in panel_bodies:\n",
        "            # Find the table within the panel-body\n",
        "            table = panel_body.find('table', {'class': 'table table-striped'})\n",
        "            if table:\n",
        "                # Find all tr elements in the table\n",
        "                tr_elements = table.find_all('tr')\n",
        "                for tr in tr_elements:\n",
        "                    # Find all td elements in the row\n",
        "                    td_elements = tr.find_all('td')\n",
        "                    # Check if the row has at least 3 columns\n",
        "                    if len(td_elements) >= 3:\n",
        "                        # Replace commas with dots in the text of the third column (index 2)\n",
        "                        if td_elements[2].string:\n",
        "                            td_elements[2].string.replace_with(td_elements[2].string.replace(',', '.'))\n",
        "\n",
        "            # Convert the table HTML to a DataFrame\n",
        "            table_df = pd.read_html(str(table))[0]\n",
        "            table_dfs.append(table_df)\n",
        "\n",
        "        # Concatenate all the DataFrames in the list to create the combined DataFrame\n",
        "        tide_table_df = pd.concat(table_dfs, ignore_index=True)\n",
        "\n",
        "        tide_table_df['DIA'] = tide_table_df['DIA'].fillna(method='ffill').astype(int)\n",
        "        tide_table_df['datetime'] = pd.to_datetime(tide_table_df['DIA'].astype(str) + '/' + month + '/' + year + ' ' + tide_table_df['HORA:MIN'], format='%d/%m/%Y %H:%M').dt.tz_localize('Etc/GMT+3')\n",
        "        tide_table_df.drop(['DIA', 'HORA:MIN'], axis=1, inplace=True)\n",
        "        tide_table_df = tide_table_df[['datetime','ALTURA (m)']]\n",
        "        tide_table_df = tide_table_df.rename(columns={'ALTURA (m)': 'height'})\n",
        "        tide_table_df.loc[:, 'FORECAST'] = False\n",
        "\n",
        "        # Merge with Forecast Tide Data\n",
        "        data = []\n",
        "        response = requests.get(PRONOSTICO_URL)\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        # Find the data you're interested in\n",
        "        table_rows = soup.find_all('tr')\n",
        "\n",
        "        for row in table_rows:\n",
        "            # Extract the text from each table cell (td element) in the row\n",
        "            cells = [cell.get_text(strip=True) for cell in row.find_all('td')]\n",
        "            data.append(cells)\n",
        "\n",
        "        # Convert the data into a DataFrame\n",
        "        tide_df = pd.DataFrame(data, columns=['port','event','Time','height','Date'])\n",
        "        tide_df = tide_df.dropna()\n",
        "        tide_df['datetime'] = pd.to_datetime(tide_df['Date'] + ' ' + tide_df['Time'], errors='coerce', format='%d/%m/%Y %H:%M').dt.tz_localize('Etc/GMT+3')\n",
        "        tide_df.drop(['Date', 'Time'], axis=1, inplace=True)\n",
        "\n",
        "        tide_df['port'].replace(r'^\\s*$', np.nan, regex=True, inplace=True)\n",
        "\n",
        "        tide_df['port'].ffill(inplace=True)\n",
        "        tide_df['height'] = tide_df['height'].str.replace('m', '').astype(float, errors='ignore')\n",
        "        tide_df['height'] = tide_df['height'].replace('---', np.NaN)\n",
        "        tide_df.dropna(subset=['height'], inplace=True)\n",
        "        tide_df = tide_df.sort_values(by='datetime')\n",
        "\n",
        "        tide_df.loc[:, 'FORECAST'] = True\n",
        "        tide_df = tide_df[tide_df['port'] == port]\n",
        "        tide_df['FORECAST'] = True\n",
        "        tide_df = tide_df[['datetime','height','FORECAST']]\n",
        "\n",
        "        tide_table_df = pd.concat([tide_table_df, tide_df], axis=0).sort_values(by='datetime')\n",
        "        df = tide_table_df\n",
        "        df.set_index('datetime', inplace=True)\n",
        "        df['nearby_true'] = df['FORECAST'].rolling('2h', center=True).max().fillna(0).astype(bool)\n",
        "        df['check'] = ~df['nearby_true']\n",
        "        filtered_df = df[df['check'] | df['FORECAST']].copy()\n",
        "        filtered_df.reset_index(inplace=True)\n",
        "        filtered_df.drop(columns=['nearby_true', 'check'], inplace =True)\n",
        "\n",
        "        tide_df = filtered_df\n",
        "\n",
        "    finally:\n",
        "        driver.quit()\n",
        "\n",
        "    return tide_df\n",
        "\n",
        "if 'app' not in globals():\n",
        "    app = Flask(__name__)\n",
        "\n",
        "    @app.route('/good_conditions', methods=['POST'])\n",
        "    def good_conditions():\n",
        "        #lat = float(request.args.get('lat', default=-34.56))\n",
        "        #lon = float(request.args.get('lon', default=-58.40))\n",
        "        lat = -34.56\n",
        "        lon = -58.40\n",
        "\n",
        "        port = 'PUERTO DE BUENOS AIRES (Dรกrsena F)'\n",
        "        forecast_df = fetch_weather(lat,lon)\n",
        "        forecast_df['IsGood?'] = False\n",
        "        all_tide_df = pd.DataFrame()\n",
        "\n",
        "        min_year, min_month = forecast_df['datetime'].min().year, forecast_df['datetime'].min().month\n",
        "        max_year, max_month = forecast_df['datetime'].max().year, forecast_df['datetime'].max().month\n",
        "\n",
        "        for year in range(min_year, max_year + 1):\n",
        "            start_month = min_month if year == min_year else 1\n",
        "            end_month = max_month if year == max_year else 12\n",
        "            for month in range(min_month, max_month + 1):\n",
        "                tide_df = generate_tide_table(str(year), str(month), port)\n",
        "                all_tide_df = pd.concat([all_tide_df, tide_df])\n",
        "\n",
        "        forecast_df['tide_height'] = round(forecast_df['datetime'].apply(lambda x: calculate_tide_height(x, all_tide_df)), 2)\n",
        "\n",
        "        for index, row in forecast_df.iterrows():\n",
        "            weather_description = row['weather'][0]['description'].upper()\n",
        "            wind_speed = row['wind_speed_knots']\n",
        "            wind_gust = row['wind_gust_knots']\n",
        "            height = row['tide_height']\n",
        "\n",
        "            if all(word not in weather_description for word in BAD_WEATHER) and GOOD_MIN_WIND <= wind_speed <= GOOD_MAX_WIND and wind_gust <= GOOD_MAX_WIND and MIN_TIDE <= height:\n",
        "                forecast_df.at[index, 'IsGood?'] = True\n",
        "\n",
        "        forecast_df = forecast_df[['datetime', 'IsGood?', 'weather_clouds', 'wind_direction', 'wind_speed_knots', 'wind_gust_knots', 'tide_height']]\n",
        "        json = forecast_df.to_json(orient='records', lines=True, compression='gzip')\n",
        "        return json\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(host='0.0.0.0', port=443)"
      ],
      "metadata": {
        "id": "CbWCj6XMVJ4v",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}